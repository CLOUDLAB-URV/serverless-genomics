"""

REMAINING THINGS TO DO:
-Implement new fasta partitioner
-Add s3 fastq location
-Improve/Remake log system
-Add the dockerfile folder
-More refactoring

"""

import argparse
import os.path
import time
import re
import sys
from random import randint
import Metadata
import fastq_functions as fq_func
import fasta_functions as fa_func
from varcall_arguments import Arguments
from pipeline_caller import PipelineCaller

# map/reduce functions and executor
from map_reduce_executor import MapReduce
from map_functions import MapFunctions

###################################################################
#### PIPELINE SETTINGS
###################################################################
parser = argparse.ArgumentParser(description='Variant Caller - Cloudbutton Genomics Use Case demo')

###################################################################
#### COMMAND-LINE ARGUMENTS
###################################################################
# File Names And Locations
# fastq in SRA database
parser.add_argument('-fq','--fq_seq_name', help='Fastq sequence name (for example SRR6052133) used for SRA database',required=False)
# fastq in s3 bucket
parser.add_argument('-fq1','--fastq1', help='Fastq file 1, stored in s3',required=False)
parser.add_argument('-fq2','--fastq2', help='Fastq file 2, stored in s3 (paired end sequencing) - optional',required=False)
parser.add_argument('-fa','--fasta',help='Fasta reference filename', required=True)
# input files locations
parser.add_argument('-cl','--cloud_adr',help='cloud provider url prefix', required=False)
parser.add_argument('-b','--bucket',help='cloud provider bucket name', required=True)
parser.add_argument('-fb','--fbucket',help='cloud provider bucket name - for fasta file', required=False)
# fastq data source (SRA or s3)
parser.add_argument('-ds','--data_source',help='Data source', required=False)

# File Splitting Parameters
parser.add_argument('-nfq','--fastq_read_n', help='Number of reads per fastq chunk ',required=False)
parser.add_argument('-nfa','--fasta_char_n',help='Number of characters per fasta chunk', required=True)
parser.add_argument('-ofa','--fasta_char_overlap',help='bp overlap between fasta chunks', required=False)

# Pipeline-Specific Parameters
parser.add_argument('-t','--tolerance',help='number of additional strata to include in filtration of map file', required=False)
parser.add_argument('-ff','--file_format',help='mpileup file format - csv or parquet', required=False)

# Run Settings
parser.add_argument('-itn','--iterdata_n',help='Number of iterdata elements to run', required=False)
parser.add_argument('-cf','--concur_fun',help='concurrent function quota limit', required=False)
parser.add_argument('-s3w','--temp_to_s3',help='Write intermediate temp files to s3 for debugging', required=False)
parser.add_argument('-rt','--runtime_id',help='runtime to use to execute the map-reduce', required=False)
parser.add_argument('-rtm','--runtime_mem',help='runtime memory to be assigned to each function - maximum 2048 MB', required=False)
parser.add_argument('-rtr','--runtime_memr',help='runtime memory to be assigned to reduce function - maximum 10240 MB', required=False)
parser.add_argument('-rts','--runtime_storage',help='runtime storage to be assigned to map function - maximum 10000 MB - currently set manually', required=False)
parser.add_argument('-bs','--buffer_size',help='memory in percentatge for buffer size - maximum 100%', required=False)
parser.add_argument('-ftm','--func_timeout_map',help='timeout for map function - maximum 900', required=False)
parser.add_argument('-ftr','--func_timeout_reduce',help='timeout for reduce function - maximum 900', required=False)
parser.add_argument('-sk','--skip_map',help='True/False; use mpileups generated by previous run, to run only reducer', required=False)
parser.add_argument('-lb','--loadbalancer',help='load balancer execution method: manual|select', required=False)

###################################################################
#### PARSE COMMAND LINE ARGUMENTS
###################################################################
def parse_optional_arg(arg_opt1, arg_opt2, text2_opt1=None, text2_opt2=None):
    out1 = ""
    out2 = ""
    if arg_opt1 is not None:
        out1 = arg_opt1
        out2 = text2_opt1
    else:
        out1 = arg_opt2
        out2 = text2_opt2
    if out2 is not None:
        return(out1, out2)
    else:
        return(out1)
    
args = parser.parse_args()

# FastQ names
fq_seqname = parse_optional_arg(args.fq_seq_name, None)
fastq_file = parse_optional_arg(args.fastq1, "")

# From input, determine whether it is paired- or single-end sequencing
fastq_file2, seq_type = parse_optional_arg(args.fastq2, "","paired-end", "single-end")
fasta_file = args.fasta

# Cloud Storage Settings
cloud_adr = parse_optional_arg(args.cloud_adr, "aws")
bucket = args.bucket
fasta_bucket = parse_optional_arg(args.fbucket, bucket)

# Fastq data source (SRA)
datasource = parse_optional_arg(args.data_source, "s3")

# File Splitting Parameters
# Fastq and fasta chunk sizes (fastq read no. multiplied by 4 to get number of lines)
fastq_read_n = int(parse_optional_arg(args.fastq_read_n, None))
fastq_chunk_size = 4*fastq_read_n  # used in the case of fastq stored in s3.
fasta_chunk_size = int(args.fasta_char_n)
fasta_char_overlap = int(parse_optional_arg(args.fasta_char_overlap, 300))

# Pipeline-Specific Parameters
tolerance = parse_optional_arg(args.tolerance, 0)
file_format = parse_optional_arg(args.file_format, "parquet")

# Run Settings
iterdata_n, function_n = parse_optional_arg(args.iterdata_n, None,args.iterdata_n, "all")
concur_fun = int(parse_optional_arg(args.concur_fun, 10000))
temp_to_s3 = parse_optional_arg(args.temp_to_s3, False)
runtime_id = parse_optional_arg(args.runtime_id, 'lumimar/hutton-genomics-v03:18')
runtime_mem = parse_optional_arg(args.runtime_mem, 1024)
runtime_mem_r = parse_optional_arg(args.runtime_memr, 4096)
runtime_storage = parse_optional_arg(args.runtime_storage, 4000)
buffer_size = parse_optional_arg(args.buffer_size, "75%")
func_timeout_map = parse_optional_arg(args.func_timeout_map, 2400)
func_timeout_reduce = parse_optional_arg(args.func_timeout_reduce, 2400)
skip_map = parse_optional_arg(args.skip_map, False)
lb_method = parse_optional_arg(args.loadbalancer, "select")

# DEBUGGING SETTINGS
gem_test=False              # To execute only the gem indexer and mapper and skip the rest of map function
pre_processing_only=False   # To skip map/reduce
debug=True                  # Keep all af.printl outputs, if not False don't print them

print("DEBUG_TEST: running only gem indexer and mapper in map function: "+str(gem_test))
print("DEBUG_TEST: running only pre-processing: "+str(pre_processing_only))

# S3 prefixes (cloud folders)
fasta_folder = "fasta/"
fastq_folder = "fastqgz/"
split_fasta_folder = "fasta-chunks/"
idx_folder = "fastq-indexes/"
out_folder = "outputs/"
s3_temp_folder = "temp_outputs/"

arguments = Arguments(fq_seqname, fastq_file, fastq_file2, seq_type, fasta_file, cloud_adr, bucket, fasta_bucket, 
                          datasource, fastq_read_n, fastq_chunk_size, fasta_chunk_size, fasta_char_overlap, tolerance, 
                          file_format, iterdata_n, function_n, concur_fun, temp_to_s3, runtime_id, runtime_mem, runtime_mem_r, 
                          runtime_storage, buffer_size, func_timeout_map, func_timeout_reduce, skip_map, lb_method, gem_test, 
                          pre_processing_only, debug, fasta_folder, fastq_folder, split_fasta_folder, idx_folder, out_folder, 
                          s3_temp_folder)
 
if __name__ == "__main__":
    pipeline = PipelineCaller()
    pipeline(arguments)